{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeppredict_2_cnn_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "FJfVqcEtUaq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting up the CNN model"
      ]
    },
    {
      "metadata": {
        "id": "sFfbc57EUoXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this project we are using Python, and Jupyter Notebooks hosted on Google Colab. Any Jupyter engine will can be used, but it will require adjustmets to this initial setup to be able to access the raw data and the helper tools. \n",
        "\n",
        "To keep the notebook clean, all the implementation details are hidden in a set of helper functions in the file `deeppredict_tools.py`"
      ]
    },
    {
      "metadata": {
        "id": "_pqVVzZCVsmf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prerequisites for running this Notebook on Google Colab \n",
        "\n",
        "We need to mount a Google Drive folder called `deeppredict`, which has the same structure and contents as the repository at https://github.com/dimitardi/deep-predict. \n",
        "\n",
        "And the matlab raw data files in the subfolder `DEEPPREDICT_HOME/dataset` (see `deeppredict_0_download_raw_data.ipynb` for how to download these files)"
      ]
    },
    {
      "metadata": {
        "id": "O0L8nInIam5E",
        "colab_type": "code",
        "outputId": "409aa3fc-800a-4500-db57-9d3fb576fec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DEEPPREDICT_HOME = '/content/gdrive/My Drive/deeppredict'\n",
        "\n",
        "# add the home folder to the python path to be able to import and use the included code\n",
        "import sys\n",
        "sys.path.append(DEEPPREDICT_HOME)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c9bb42e7-fac7-4ef6-e623-db364c4d60c8",
        "id": "eNI_6w6wkHFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q -r '/content/gdrive/My Drive/deeppredict/requirements.txt'\n",
        "\n",
        "import skimage as sk\n",
        "# explicitly check the sci-kit image version\n",
        "# currently colab has the 0.13 by default, which is too old. It should be at least >= 0.14\n",
        "sk.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.14.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "V60nXrE0H561",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN Architecture\n",
        "\n",
        "For this use-case we chose an architecture mimicking the Guo et al. one, described in the research article [Deep Learning Enabled Fault Diagnosis Using Time-Frequency Image Analysis of Rolling Element Bearings](https://www.hindawi.com/journals/sv/2017/5067651/)\n",
        "\n",
        "We use the following hyperparameters:"
      ]
    },
    {
      "metadata": {
        "id": "KP0nRVS6NOMv",
        "colab_type": "code",
        "outputId": "5103f10d-1d62-48b1-94b6-da512b33852d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "## input data parameters\n",
        "IMAGES_SHAPE = (96, 96, 4)\n",
        "PADDING = 'same'\n",
        "KERNEL_SIZE = (5, 5)\n",
        "KERNEL_INITIALIZER = 'glorot_normal'\n",
        "# parameters for deep layers\n",
        "NUMBER_OF_CLASSES = 3  # N, IR and B\n",
        "DROPOUT = 0.5\n",
        "LEAK_ALPHA = 0.1\n",
        "MAX_POOLING_POOL_SIZE = (2, 2)\n",
        "ACTIVATION_LAYER_FUNCTION = 'softmax'\n",
        "# loss and optimizer\n",
        "LOSS_FUNCTION = 'categorical_crossentropy'\n",
        "LEARNING_RATE = 0.001\n",
        "OPTIMIZER = optimizers.Adam(LEARNING_RATE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UKCOByZ_NNP8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The reasons behind the choice of the hyperparameters are too broad to describe here. \n",
        "\n",
        "However, an example of how we found a good learning rate using the **cyclical learning rate** approach is described [in this Jupyter Notebook from our repository](https://github.com/dimitardi/deep-predict/blob/master/deeppredict_A1_finding_learning_rate.ipynb)."
      ]
    },
    {
      "metadata": {
        "id": "Fdd3YGl-NHym",
        "colab_type": "code",
        "outputId": "b1c00f09-c90a-40db-8b45-8a0876cb22a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras import metrics\n",
        "\n",
        "\n",
        "# CNN architecture from Guo et al.\n",
        "model = Sequential()\n",
        "model.add(Conv2D(5, KERNEL_SIZE,                  \n",
        "                 input_shape=IMAGES_SHAPE,\n",
        "                 data_format='channels_last',\n",
        "                 kernel_initializer=KERNEL_INITIALIZER,                 \n",
        "                 padding=PADDING))\n",
        "model.add(LeakyReLU(LEAK_ALPHA))\n",
        "model.add(Conv2D(10, KERNEL_SIZE, \n",
        "                 kernel_initializer=KERNEL_INITIALIZER,\n",
        "                 padding=PADDING))\n",
        "model.add(LeakyReLU(LEAK_ALPHA))\n",
        "model.add(MaxPooling2D(pool_size=MAX_POOLING_POOL_SIZE))\n",
        "model.add(Conv2D(10, KERNEL_SIZE, \n",
        "                 kernel_initializer=KERNEL_INITIALIZER,\n",
        "                 padding=PADDING))\n",
        "model.add(LeakyReLU(LEAK_ALPHA))\n",
        "model.add(MaxPooling2D(pool_size=MAX_POOLING_POOL_SIZE))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(LeakyReLU(LEAK_ALPHA))\n",
        "model.add(Dense(5))\n",
        "model.add(LeakyReLU(LEAK_ALPHA))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(NUMBER_OF_CLASSES))\n",
        "model.add(Activation(ACTIVATION_LAYER_FUNCTION))\n",
        "  \n",
        "model.compile(loss=LOSS_FUNCTION, \n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=[metrics.categorical_accuracy])\n",
        "\n",
        "filename_for_model = f'{DEEPPREDICT_HOME}/models/CNN_arch_guo_shape96-96-4-3__initial.h5'\n",
        "model.save(filename_for_model)\n",
        "print(f'Saved a new initial model at {filename_for_model}')\n",
        "  \n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Saved a new initial model at /content/gdrive/My Drive/deeppredict/models/CNN_arch_guo_shape96-96-4-3__initial.h5\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 96, 96, 5)         505       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 96, 96, 5)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 96, 96, 10)        1260      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 96, 96, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 48, 48, 10)        2510      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 48, 48, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5760)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                57610     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 18        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 61,958\n",
            "Trainable params: 61,958\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}